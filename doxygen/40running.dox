/*!
\page running Running \bdmpi Programs
\tableofcontents


For the purpose of the discussion in this section, we will use the simple "Hello
world" \bdmpi program that is located in the file \c test/helloworld.c of
\bdmpi's source distribution. This program is listed bellow:

\par
\verbinclude helloworld.c

This program has its process print its parent and own process ID along with its rank
in the \c MPI_WORLD_COMM and the size of that communicator. Note that the calls to
MPI_Barrier() are used to ensure that the output from the different processes is
displayed in an orderly fashion.

This program can be compiled by simply executing
\verbatim
bdmpicc -o helloworld test/helloworld.c
\endverbatim
and is also been automatically built during \bdmpi's build process and resides in 
the \c build/Linux-x86_64/test directory.



<!-- ----------------------------------------------------------------------------- -->
---
\section onenode Running on a single node 


\bdmpi provides the \c bdmprun command to run \bdmpi program on a single node. For
example, the following command

\verbatim
bdmprun -ns 4 build/Linux-x86_64/test/helloworld
\endverbatim

will create a single master process that will spawn four slave processes (i.e., due to
<tt>-ns 4</tt> option), each executing the \c helloworld program. Here is a sample
output of the above execution:

\par
\verbinclude helloworld.1

The first four lines came from the \c helloworld program itself, whereas the remaining 
output lines came from \c bdmprun. Looking at this output we can see that all four
processes share the same parent process, which corresponds to the master process, 
\c bdmprun. The master process reports the timing 
statistics at the end of the execution of \c helloworld. 



<!-- ----------------------------------------------------------------------------- -->
---
\section manynodes Running on multiple nodes 

In order for a program to run at multiple nodes, \c bdmprun needs to be combined with
the \c mpiexec command that is provided by \mpi. For example, the following command

\verbatim
mpiexec -hostfile ~/machines -np 3 bdmprun -ns 4 build/Linux-x86_64/test/helloworld
\endverbatim

will start three master processes (i.e., due to <tt>-np 3</tt>) and each master
process will spawn four slaves, resulting at a total of 12 processes executing the \c
helloworld program. Here is a sample output of the above execution:

\par
\verbinclude helloworld.2

Notice that the parent process IDs of the different \bdmpi processes reveal the
master-slave relation that exists (e.g., ranks 0--3, 4--7, and 8--11 have the same
parent process). Also, the output lines generated by \c bdmprun provide information as to
the machine on which the particular master process was executed (e.g., \c bd1-umh, \c
bd2-umh, and \c bd3-umh) and overall timing information. The names of these machines
are specified in the \t machines file that was provided as the \c -hostfile of \c
mpiexec, following \c mpiexec's host machine specification guidelines (see MPICH 
documentation).

Do not configure your hostfile to have \c mpiexec start multiple processes on
the same node. If you do, then each node will have multiple master processes
running on it (i.e., multiple instances of \c bdmprun), each of which will have its
own set of slave processes. If you wish to have multiple slave processes run at
once on the same node, use the \c -nr option instead.


<!-- ----------------------------------------------------------------------------- -->
---
\section bdmprun Options of bdmprun 

There are a number of optional parameters that control <tt>bdmprun</tt>'s execution. You
can get a list of these options by simply executing <tt>bdmprun -h</tt>, which will
display the following:

\par
\verbinclude bdmprun.help



<!-- ----------------------------------------------------------------------------- -->
\subsection execoptions Options related to the execution environment 

The \c -ns, \c -nr, \c -nc, and \c -wd options are used to control the execution 
environment of a \bdmpi job.

The \c -ns option specifies the number of slaves that \c bdmprun will spawn on each
node. These slaves then proceed to execute the provided \bdmpi program (i.e., \c
exefile). If multiple instances of \c bdmprun are started via \c mpiexec, then the
total number of processes that are involved in the parallel execution of \c exefile
is <tt>np*ns</tt>, where \c np is the number of processes specified in \c mpiexec and
\c ns is the number of slaves supplied via the \c -ns option. In other words, the
size of the \c MPI_COMM_WORLD communicator is \c np*ns.

The \c -nr options specifies the number of slave processes spawned by a single \c
bdmprun process that are allowed to be executing concurrently. This option enables
\bdmpi's node-level cooperative multitasking execution model, which is designed to
ensure that the aggregate memory requirements of the concurrently executing processes
do not overwhelm the amount of available physical memory on the system. The default
value for \c -nr is one, allowing only one slave to be executing per master process
at a time. However, for multi-core systems, \c -nr can be increased as long as the
aggregate amount of memory required by the concurrently running processes can
comfortably fit within the available memory of the system. For example, 

\verbatim
mpiexec -hostfile ~/machines -np 3 bdmprun -ns 4 -nr 2 build/Linux-x86_64/test/helloworld
\endverbatim

will allow a maximum of two slave processes on each of the three nodes to be
executing concurrently. The value specified for \c -nr should be less than or equal
to \c -ns. 

Besides the aggregate memory requirements, another issue that needs to be considered
when the number of running processes is increased is the capability of the underlying
I/O subsystem to handle concurrent I/O operations. On some systems, a faster
execution can be obtained by allowing multiple slave processes to run concurrently
but reduce the concurrency allowed during I/O operations. To facilitate this, \bdmpi
provides a pair of API functions that implement critical sections, which limit the
number of processes that can be at a critical section at any give time. These are
described in \ref bdmpimutex. The number of slave processes that are allowed to be
running at a critical section is controlled by <tt>bdmprun</tt>'s \c -nc option, which
should be less than or equal to the value specified for \c -nr.

Finally, the \c -wd option specifies the name of the directory that \bdmpi will use
to store the various intermediate file that it generates. Since \bdmpi's execution
is primarily out-of-core, this directory should be on a drive/volume that has a
sufficient amount of available storage and preferably the underlying hardware should
support fast I/O.


<!-- ----------------------------------------------------------------------------- -->
\subsection memoptions Options related to memory resources

The \c -sm, \c -mm, \c -im, \c -pg, \c -rm, \c -mt, and \c -sbma options are
used to control various aspects of the execution of a \bdmpi program as it
relates to how it uses the memory. Among them, \c -im, \c -rm, and \c -sbma
are the most important, whereas \c -sm, \c -mm, and \c -pg are provided for
fine tuning and most users will not need to modify them. Note that for all
memory-related options, the size is specified in terms of memory pages and not
bytes. On Linux, a memory page is typically 4096 bytes.

The \c -sm option specifies the amount of shared memory to allocate for each
slave process. This memory is used to facilitate fast communication between
the master and the slave processes via \c memcpy(). The \c -mm option
specifies the size of the buffer that a master process will allocate for
inter-node communication. Note that if the data that needs to be communicated
between the master and the slaves or other masters exceeds is greater than
what is specified by these options, the transfer is done in multiple steps.
Thus, the values of these options do not impact the correctness of the
execution, but if they are relatively small, may lead to (somewhat) higher
communication cost.

Since processes in \bdmpi can be suspended and as such are not available to
receive data sent to them, the master processes buffer data at the message's
destination node. The \c -im parameter controls if the message will be
buffered in DRAM or if it will buffered on disk. Messages whose size is
smaller than the value specified by \c -im are buffered in memory, otherwise
they are buffered on disk. The only exception to the above rule are the
broadcast and the reduction operations, in which the buffering is always done
in memory. Also note that in the case of collective communication operations,
the size of the message is defined to be the amount of data that any processor
will need to send/receive to/from any other processor.

As discussed in \ref sbmalloc, \bdmpi uses its own dynamic memory allocation
library that bypasses the system's swap file and preserves the data and
virtual memory mappings throughout the execution of the program. The \c -sbma
option controls the desired memory exchange strategy to be used during program
execution. If this option is omitted, then no memory exchange strategy will be
employed and the application will rely on the OS swapping mechanism exactly as
if the standard C dynamic memory library were in use. If a valid memory
exchange strategy is chosen, then the \c -pg parameter controls the resolution
at which the sbmalloc library tracks memory operations and transfers data
between disk and RAM. The \c -rm parameter is relevant only for lazy writing
memory exchange strategies and controls the maximum amount of resident memory,
aggregated across all processes of the \bdmpi execution, which is allowed
before a process is chosen to evict its resident memory.

To facilitate the exchange of data between RAM and secondary storage, it is
necessary for the sbmalloc subsystem to grant write permissions to an
allocation prior to being loaded. In case the application involves multiple
threads accessing shared allocations, this can cause incorrect execution due
the following race condition. If one thread tries to write to an allocation,
while another thread is loading the allocation, then data may be lost. For
such applications it is necessary to specify the \c -mt option. This will
enable a runtime feature of the sbmalloc subsystem which peforms the load
atomically by leveraging the OS memory mapping API, but comes at the cost of a
small performance penalty.

<!-- The \c -sb parameter controls the size of the allocations that will be
handled by the sbmalloc subsystem. Any allocation that is smaller than the
value specified by \c -sb, is handled by the standard \c malloc() library,
whereas the rest of the allocations are handled by sbmalloc. If you want to
entirely disable sbmalloc, you can specify 0 as the value for this option. -->


<!-- ----------------------------------------------------------------------------- -->
\subsection otheroptions The remaining options 

The last two options, \c -dl and \c -h, are used to turn on various reporting
messages and display <tt>bdmprun</tt>'s help page. Setting \c -dl to anything else
than 0 can potentially generate a lot of reporting messages and is not encouraged. It
is there primarily for debugging \bdmpi during its development.




*/
